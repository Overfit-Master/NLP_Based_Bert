{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 文本分类实例"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5041388e0e074a2b8fa4a78d4424a810"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7766\n"
     ]
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/7766 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d1e1bb126ba447d9c6f1e5bcd07802e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7765\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['label', 'review'],\n        num_rows: 6988\n    })\n    test: Dataset({\n        features: ['label', 'review'],\n        num_rows: 777\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过新方法加载数据和数据清洗\n",
    "import datasets\n",
    "dataset = datasets.load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split=\"train\")\n",
    "print(len(dataset))\n",
    "dataset = dataset.filter(lambda x: x[\"review\"] is not None)\n",
    "print(len(dataset))\n",
    "# 划分数据集\n",
    "split_dataset = dataset.train_test_split(test_size=0.1)\n",
    "split_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6988 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f26fbdcc391545ea9974827c0623fa10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/777 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d33605fe3eae4f4285e97eb46e884732"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 6988\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 777\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行分词\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "def process_function(example):\n",
    "    tokenized_example = tokenizer(example[\"review\"], max_length=128, truncation=True)\n",
    "    tokenized_example[\"labels\"] = example[\"label\"]\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_datasets = split_dataset.map(function=process_function, batched=True, remove_columns=split_dataset[\"train\"].column_names)\n",
    "\n",
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 创建dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "train_loader = DataLoader(tokenized_datasets[\"train\"], batch_size=32, shuffle=True, collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "\n",
    "valid_loader = DataLoader(tokenized_datasets[\"test\"], batch_size=64, shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 6821,  702,  ...,    0,    0,    0],\n        [ 101,  868,  711,  ...,    0,    0,    0],\n        [ 101, 3302, 1218,  ...,    0,    0,    0],\n        ...,\n        [ 101, 4692, 6814,  ...,  817, 2347,  102],\n        [ 101, 1343, 5722,  ..., 2791, 7313,  102],\n        [ 101, 2137, 4638,  ..., 6574, 7030,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n        0, 0, 1, 1, 1, 1, 1, 1])}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(train_loader))[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch\n",
    "\n",
    "# 模型及优化器定义\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\")\n",
    "optimizer = Adam(model.parameters(), lr=0.00002)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(epochs, log_step=30):\n",
    "    for epoch in range(epochs):\n",
    "        step=0\n",
    "        model.train()\n",
    "        print(f\"<<<<<<<<Training on epoch{epoch} >>>>>>>>\")\n",
    "        for batch in train_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % log_step == 0:\n",
    "                print(f\"global_step: {step}, loss: {output.loss.item()}\")\n",
    "            step += 1\n",
    "        print(evaluate())\n",
    "\n",
    "\n",
    "# 模型验证\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    # 该方法比no_grad()更加的优化了测试的内存管理方面\n",
    "    with torch.inference_mode():\n",
    "        for batch in valid_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            clf_metrics.add_batch(predictions=pred, references=batch[\"labels\"])\n",
    "    return clf_metrics.compute()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<Training on epoch0 >>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31825\\.conda\\envs\\transformers\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 0, loss: 0.6473658084869385\n",
      "global_step: 30, loss: 0.6436285972595215\n",
      "global_step: 60, loss: 0.4400003254413605\n",
      "global_step: 90, loss: 0.2691814601421356\n",
      "global_step: 120, loss: 0.27176809310913086\n",
      "global_step: 150, loss: 0.19636385142803192\n",
      "global_step: 180, loss: 0.1395656019449234\n",
      "global_step: 210, loss: 0.473237544298172\n",
      "{'accuracy': 0.8957528957528957, 'f1': 0.9236569274269557}\n",
      "<<<<<<<<Training on epoch1 >>>>>>>>\n",
      "global_step: 0, loss: 0.5004894733428955\n",
      "global_step: 30, loss: 0.2739998698234558\n",
      "global_step: 60, loss: 0.3139651119709015\n",
      "global_step: 90, loss: 0.45809096097946167\n",
      "global_step: 120, loss: 0.17288801074028015\n",
      "global_step: 150, loss: 0.25362280011177063\n",
      "global_step: 180, loss: 0.35154789686203003\n",
      "global_step: 210, loss: 0.3060349225997925\n",
      "{'accuracy': 0.8970398970398971, 'f1': 0.9229287090558767}\n",
      "<<<<<<<<Training on epoch2 >>>>>>>>\n",
      "global_step: 0, loss: 0.11527769267559052\n",
      "global_step: 30, loss: 0.2694074511528015\n",
      "global_step: 60, loss: 0.1163197010755539\n",
      "global_step: 90, loss: 0.11627474427223206\n",
      "global_step: 120, loss: 0.15551283955574036\n",
      "global_step: 150, loss: 0.16791506111621857\n",
      "global_step: 180, loss: 0.1959286332130432\n",
      "global_step: 210, loss: 0.1451648324728012\n",
      "{'accuracy': 0.9047619047619048, 'f1': 0.9312267657992565}\n",
      "<<<<<<<<Training on epoch3 >>>>>>>>\n",
      "global_step: 0, loss: 0.09690231084823608\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epochs, log_step)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m----> 9\u001B[0m         batch \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mcuda() \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m     10\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     11\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatch)\n",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m----> 9\u001B[0m         batch \u001B[38;5;241m=\u001B[39m {k: \u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m     10\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     11\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatch)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "test = \"这家酒店不错，饭很好吃\"\n",
    "with torch.inference_mode():\n",
    "    test_tensor = tokenizer(test, return_tensors=\"pt\")\n",
    "    test_tensor = {k: v.cuda() for k, v, in test_tensor.items()}\n",
    "    test_result = model(**test_tensor).logits\n",
    "    pred = torch.argmax(test_result, dim=-1)\n",
    "    print(pred.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 创建pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_1', 'score': 0.9989665746688843}]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"这家酒店不错，饭很好吃\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
