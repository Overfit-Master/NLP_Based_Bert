{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 文本分类实例"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      label                                             review\n0         1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n1         1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n2         1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n3         1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n4         1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风\n...     ...                                                ...\n7761      0  尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...\n7762      0  盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...\n7763      0  看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...\n7764      0  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...\n\n[7766 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7761</th>\n      <td>0</td>\n      <td>尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...</td>\n    </tr>\n    <tr>\n      <th>7762</th>\n      <td>0</td>\n      <td>盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...</td>\n    </tr>\n    <tr>\n      <th>7763</th>\n      <td>0</td>\n      <td>看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...</td>\n    </tr>\n    <tr>\n      <th>7764</th>\n      <td>0</td>\n      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n    </tr>\n    <tr>\n      <th>7765</th>\n      <td>0</td>\n      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7766 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "import pandas as pd\n",
    "csv_file_path = \"ChnSentiCorp_htl_all.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.core.indexing._iLocIndexer at 0x1842c452f40>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据清洗\n",
    "data = data.dropna()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 创建dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.data = pd.read_csv(csv_path).dropna()\n",
    "        # self.data = self.data.dropna()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # 此处的comment仍是文本不是tensor\n",
    "        # 单条处理比不过batch处理速度，所以传入DataLoader之后再进行处理\n",
    "        # fixme 此索引方式在进行去重后会出现问题，进行更改\n",
    "        # label = self.data[\"label\"][item]\n",
    "        # comment = self.data[\"review\"][item]\n",
    "        return self.data.iloc[item][\"review\"], self.data.iloc[item][\"label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', 1)\n",
      "('商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', 1)\n",
      "('早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。', 1)\n",
      "('宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小，但加上低价位因素，还是无超所值的；环境不错，就在小胡同内，安静整洁，暖气好足-_-||。。。呵还有一大优势就是从宾馆出发，步行不到十分钟就可以到梅兰芳故居等等，京味小胡同，北海距离好近呢。总之，不错。推荐给节约消费的自助游朋友~比较划算，附近特色小吃很多~', 1)\n",
      "('CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风', 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "7765"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据集\n",
    "dataset = CommentDataset(csv_file_path)\n",
    "for i in range(5):\n",
    "    print(dataset[i])\n",
    "dataset.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(6989, 776)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行数据集的划分\n",
    "from torch.utils.data import random_split\n",
    "train_set, valid_set = random_split(dataset, lengths=[0.9, 0.1])\n",
    "len(train_set), len(valid_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('非常好！一进房间就能闻到一股花得芳香~~~服务态度十分热情~~~酒店里不但有免费得室内室外温泉泡~~而且还送两张188元得温泉泡~~有不下七十多种温泉：如白酒温泉，绿茶温泉等十分不错~~早饭也相当丰盛可以说应有尽有~~鸡翅特别美味~~通过携程预订还送免费得两杯饮料~~~sogood~~是标准得五星酒店~~~如果觉得离市区远了点可以乘班车或打车（40元左右）~~但绝对物超所值~~走时还送了两串玛瑙手机链~~~下次再去厦门一定要再去~~Imissyou！！', 1), ('房间尚可，环境也不错，只是周边环境不够理想！稍微差了点！', 1), ('我住的158的房,觉得还可以,房间正对酒店大门口的马路,隔音还可以,不吵.卫生间也不是太少,就是设计不太合理,洗澡的龙头力道太大,水打在身上都疼.综合来说还可以.', 1), ('总体感觉不错，性价比挺高的，旁边有个银座，银座下面还有个超市', 1), ('地点在十字路口边上，十分嘈杂，巴士车呼啦啦直到夜里11点。房间很小，洗漱用品不全：沐浴液、洗发液和洗手液是三合一的，很不好用。服务态度不好。电话查询时总是让你听音乐等待很长时间，然后无故将你电话挂断。多算了我一份早餐。', 0), ('地理位置较优越，房间内干净整洁，不能说很安静但出门在外凡事不能太叫真，隔音还是可以的，可以考虑无烟楼层的房间较安静，总台小姐的服务态度还是可以的，外出旅游住宿可以建议考虑此酒店，去王兴记吃虾肉馄饨或去三凤桥买酱排骨还是很方便的，谢谢！', 1), ('如果去成都,在这里居住不错,行程方便,其他的都很差.最气的是请客人吃饭结完帐,很久以后到房间说台布被烫了,硬是要赔500大洋.', 0), ('10月初回黑龙江的时候住了一晚，我所有的评价都是基于齐齐哈尔本地的情况做的，我觉得没办法和北京、上海等大城市的同级别酒店比较。周边环境还不错，楼下基本随时有出租车等着，附近还有商场和超市。服务很好，主动热情，雨伞忘服务台了，很主动的提醒我。没有骚扰电话。稍微有点噪音，走廊的服务台的电话声偶尔能听到。没带电脑，网络情况不知道。因为火车时间的问题，本来打算延迟一小时退房，服务台主动给延长了2个小时。中央空调也还好，不知道冬天会怎么样，淋浴热水很好。', 1), ('我住的是两室一厅的房间,在17楼.虽然只住了一夜,但总体来说,对这个公寓感觉不错.就是有几点不满意:1.地方确实不好找,没有醒目的标志,第一次去还真难找.2.没有一次性拖鞋,而是塑料拖鞋.3.浴缸很大,但是没有浴帘,我们住的那间,浴室的门都坏了.4.并没有两个卫生间,只是把一间分成了两间.不足的地方就这些,总体给我的感觉像家一样,有客厅和厨房,感觉很温馨.床很舒服,地方也很安静,能休息好,前台服务态度也很好,.下次去还是愿意住这里.', 1), ('实在对不起四星的称呼!12月份在2--14度的气温下,只在晚上8点后才开空调!下半夜又关闭!投诉后还有理说是响应政府号召:节约能耗.这样的HOTEL朋友们您还敢入住吗?', 0), ('还可以,不过第一次入住的时候没有送水果,这次送了,不过第二天把我第一天存的水果换了,虽然房务中心帮我换了两个苹果,不过一个坏的,不过总体还可以,听说马上要涨价了,因为听说评上了四星级,哎', 1), ('我本人办的有锦江之星的会员卡，相对来说锦江住的比较多，石家庄的锦江我只住过平安大街店，感觉非常不错，这次是因为平安大街的锦江之星没有商务房了，所以才选择了从未住过的如家。如家，外人的评价一直挺不错的，我就亲身去感受了一下，感觉非常失望。这是我第一次入住如家，不知道是不是这家酒店的使用率太高了，设施都比较陈旧。浴巾的边沿部分都磨烂了，被子也感觉洗了很多次旧旧的。周六外出游玩回来的时候竟然发现浴室的梳子没有更换、香皂没有更换，黄色牙刷的刷头与握柄中间竟然有黑黑的东西，看起来好脏。一般酒店的隔音都不会很好，可是我没想到如家国大店的隔音竟然差到门口塑料袋的摩擦声都可以听得到。而且浴室特别小，唯一比较满意的地方大概就是工作人员的服务了，还不错，总之，我不会再去第二次如家了，太差了，让我很失望，对不起这个价格。补充点评2008年7月28日：以上评价只代表我和我老公的意见，只把我们入住时遇到的情况写了出来，可能我们遇到的只是个案，不过让我感到失望是真的。另外再补充一点，如家的前台工作人员，穿的花衬衫确实有热带风情，只是感觉很花哨，不喜欢。', 0), ('这个宾馆真是神奇:1,从早上7点多开始放大声的背景音乐一直到晚上11点多,而且一直是同一张CD,简直会让人发疯.我和朋友开玩笑说,宾馆应该给每个入住的客人都发一个耳塞,这样客人不会发疯.我们第二天就搬家了.天哪!2,宾馆宣传的照片跟实际完全不符.照片上看房间超豪华,五星水准.实际是3星水准.空调除了发出噪音外,根本不制热.房间的门是关不上的,宾馆解释说只有在冬天的时候,门缩水了才能关上.电视机是不能看的.所以说平遥的星级是不能相信的.但是如果不是自己亲自来,真的想象不出差距会这么大.3,早餐上的咖啡比速溶咖啡都差,牛奶是掺水的.4,房价是780元.大家自己决定去不去住吧.后来我们搬到天元奎去了.好了很多,价格也便宜.里面的服务生也特别好.云锦诚在当地排场挺大,但是口碑不怎么样.我们这种不是政府官员的人不太适合这种地方.我从来没住过这么差的宾馆.', 0), ('酒店环境，服务和去景区都很方便。因为有过被半夜问要不要特殊服务电话骚扰的经历，所以晚上一回到房间就把电话线拔掉，但是在快上床休息时响起了敲门声，LP大人去开的门，敲门的人说敲错了，哈哈！一夜不再受骚扰。', 1), ('酒店服务还不错,在宜宾已经很好了.但是携程的价格一点都没有,豪标B在前台打折价265,携程263,希望以后携程要大大改进价格偏偏高的问题,才能有吸引了!!!', 1), ('好像跟洪崖洞酒店一个公司的，所以房间的风格比较接近，就是小一些，整体来说比较不错，房间内食品都是免费，很实在。就是早餐实在不敢恭维，大堂环境比较差。整体来说不错，属于比较好的三星级酒店。', 1), ('携程的房价偏贵了，而且房间偏小了。其他，酒店应该是现在南通最好的了吧', 1), ('2楼的标准间非常非常好，房间很大，床很舒服，隔音也不错，空调足够暖，卫生间尤其棒，非但大而且浴缸是个木桶，泡了半个小时舒服极了。但是温泉性价比不高，池子比较少，游泳池的水也太冷了。倒是那个室外的，虽然不大，但是我去的那天正好下着雪，所以感觉很好。早餐一般，倒是一楼的中餐厅的东西不错，价格不贵味道却很好，量也比较足。', 1), ('我对这家酒店非常非常的满意！！在朋友的推荐下，订了丽江束河吉奥古客栈三天。首先要说一下丽江的出租车司机不能信！当天一下飞机就遇到了貌似老实善良的纳西出租车司机，他很热情的给我介绍了许多当地的特色，给了我许多建议，让我觉得很温暖，后来他问我有没有订到酒店，我说订了，是丽江束河的束奥古客栈，他说现在太晚了，我一个女孩子现在过去他的的出租车只能到古镇门口进不去，我一个人现在去那边不安全，他可以给我找一家条件相当而且价格便宜的酒店，当时一晕就相信了，结果他把我带到了城边一个小客栈，没有热水，没有服务员，没有空调，什么都没有，便宜倒是便宜了，才80元。出租车收了我120元。当晚在郁闷中渡过。第二天换到了吉奥古，感觉非常好，既可以享受纳西庭院暖暖的阳光，又可以享受现代酒店的舒适。一进门他们的员工在吃饭，老板娘就招呼我要不要一起吃，小弟就过来给我提行旅了，下午座在小院里和老板娘喝茶聊天（免费的哦）我才知道这家酒店入住三晚以上是免费接机的，三晚以下收80元（含过路费接机），丽江城随时免费接，可以直接联系0888-5136618。晚上老板娘去古城玩，就把我也带上了，座她的车去的，没有去酒吧街的酒吧，去了家原创民谣吧，感觉很好，叫D调，我只花了15元就听了一晚上的歌，晚上和老板娘一起回来。走的时候80元直接把我送机场，出租车要100元。这家酒店给我的感觉很好，因为就像到了朋友家。补充点评2008年3月25日：最要强调的一点就是丽江的出租车司机推荐的酒店千万不能信！！还有就是买东西的话束河比古镇要便宜许多。这家客栈的条件应该是束河最好的了，特别是卫生间，唯一不足的就是房间小了点，虽然是客栈地，但是比有的三、四星的条件还要好，关键是人很好玩，没有酒店的生硬，大家随意但不随便，特别是老板娘那种边玩边做的心态让你觉得真的很丽江！', 1), ('建议订别的酒店,省得心痛,因为这家酒店在我看来是多么的糟糕', 0), ('不管是服务还是硬件都绝对够不上四星级，尽管前台确实挂着四星的牌子！！！依我看，就3星还不到。不过价格也步态四星级。', 0), ('酒店的环境不错，属于闹中取静。但是房间有点小，早餐太贵了，品种也不多。不过交通还算方便，离地铁不远。', 1), ('酒店地点很好，海景房窗外的景色也很美。可以看到栈桥和小青岛，隔海就是沙滩。服务很体贴，很喜欢楼层的小零食吧。房间设置也很周到。虽然不大，但是个很好的度假酒店。美中不足，隔音设施不太好，遇到夜间大吵大闹的邻居，就比较惨了。', 1), ('我住的A楼的豪华大床房，248元，房间很宽敞，干净。床也够大。宽带速度不错。但由于临近步行街，对面又有一个娱乐场所，所以无论早晚都很吵。不好热闹的朋友最好选择B楼。建议酒店加强一下隔音措施。前台的服务态度很好，但提醒需要使用信用卡预授权的朋友，酒店不能取消预授权（至少我是遇到了），要一个月后才能自动取消，在解决这个事情的过程中，前台服务员一直很热情，反而一个看起来像是大堂经理麽样的女人（戴眼镜），对我的询问很是不耐烦。另外携程的价格根本没有任何优势！早餐还算是物有所值的。总体来说，在要求不高的情况下还是值得一住的。', 1), ('酒店离开市区挺远，很不方便。除了大堂气派，房间根本没有五星，充其量较差的四星，更莫名其妙的是房间竟然没有暖空调，下次决不考虑入住。', 0), ('优点：1）和汽车站在一个院子内，出行便利2）斜对面就是大排挡一条街，各种小吃和水果一应俱全缺点：服务员态度一般，服务水平有待提高', 1), ('如果在遂宁这座小城里寻找温馨的家，明星康年是我首要选泽，因为她确实给人以温暖，给人以安宁，给人以留连。可以说，我是看着她成长起来的，从几年前第一天开张，到现在的逐渐成熟，都给人留下了深刻的印象。当然，目前还有不足（客人停车过夜收费、长途还不能免费），我相信，随着她的进一步成长，她将变得尽善尽美，这也是我对她的祝福！', 1), ('实在是差啊!!我当晚住的是双人房,三楼餐厅旁,一路的黑灯瞎火,还有一股味!!!', 0), ('我买的是“亲子套票”。该酒店的硬件很好！房间的东西很新，而且很干净，不愧是国际品牌！对于楼下所说的那些抱怨问题，本人也碰到了。但都能很好地解决！在此建议大家在出发前多花点时间打电话和酒店预先沟通，就会减少麻烦！还能免费升级到行政楼层的海景房。', 1), ('也许黄金海岸有自己的酒店评级机构,给此中心评了个\"四星\",不然不好意思收四五百的房租啊!也就二星的标准,大堂里蚊子那叫一个多...卫生间和浴室的门都关不上,的用手扶着!电话不响,得用自己的手机.毛巾不知是哪年的了，估计本世纪初的产品。装修用的是最低档的地砖和大理石...另外，当地民风极差，无论你在酒店里，海滩上，外面餐馆，只要你出手消费，必定挨宰！下次宁愿远赴青岛威海，也不来黄金海岸，南戴河了。海水的品质，也如当地酒店和民风，差！', 0), ('前台的MM很不错，效率高，态度也非常好。', 1), ('虽说是4星，但服务绝对是5星的。从进入酒店就有人问候，入住和退房的速度都很快。房间的布置和设施也很让人满意，一进去就有舒适的感觉。住了很多次，每次选酒店都会选它。对于在开发区办事的人，绝对是首选。', 1)]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# 尝试改写collate_fn使得文本转变为tensor\n",
    "# 先看传入collate_fn的是什么格式的数据\n",
    "def test_collate(batch):\n",
    "    print(batch)\n",
    "    print(len(batch))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=test_collate)\n",
    "for t1, t2 in enumerate(train_loader):\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 根据上述输出结果可知，传入collate_fn的数据为一个batch的数据\n",
    "# 格式为list[tuple(data, label) * batch_size]\n",
    "# 此部分编写实现将comment通过分词器转为tensor的fn\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "def collate_function(batch):\n",
    "    comments, labels = [], []\n",
    "    # batch为list，依次访问进行存储\n",
    "    for i in batch:\n",
    "        comments.append(i[0])\n",
    "        labels.append(i[1])\n",
    "\n",
    "    inputs = tokenizer(comments, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = torch.tensor(labels)\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 4507,  754,  ...,  510,  671,  102],\n        [ 101, 3302, 1218,  ...,    0,    0,    0],\n        [ 101, 2682, 2454,  ...,    0,    0,    0],\n        ...,\n        [ 101, 5381,  677,  ..., 3952, 4381,  102],\n        [ 101,  122,  510,  ...,    0,    0,    0],\n        [ 101, 1762, 3315,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 0, 0, 1])}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate_function)\n",
    "valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False, collate_fn=collate_function)\n",
    "\n",
    "next(enumerate(train_loader))[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# 模型及优化器定义\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\")\n",
    "optimizer = Adam(model.parameters(), lr=0.00002)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(epochs, log_step=10):\n",
    "    for epoch in range(epochs):\n",
    "        step=0\n",
    "        model.train()\n",
    "        print(f\"<<<<<<<<Training on epoch{epoch} >>>>>>>>\")\n",
    "        for batch in train_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % log_step == 0:\n",
    "                print(f\"global_step: {step}, loss: {output.loss.item()}\")\n",
    "            step += 1\n",
    "        evaluate()\n",
    "\n",
    "\n",
    "# 模型验证\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    # 该方法比no_grad()更加的优化了测试的内存管理方面\n",
    "    with torch.inference_mode():\n",
    "        for batch in valid_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "                output = model(**batch)\n",
    "                pred = torch.argmax(output.logits, dim=-1)\n",
    "                for p, l in zip(pred, batch[\"labels\"]):\n",
    "                    if p == l:\n",
    "                        acc_num += 1\n",
    "        print(f\"acc: {acc_num / len(valid_set)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<Training on epoch0 >>>>>>>>\n",
      "global_step: 0, loss: 0.6822832226753235\n",
      "global_step: 10, loss: 0.5704638361930847\n",
      "global_step: 20, loss: 0.48738840222358704\n",
      "global_step: 30, loss: 0.5126784443855286\n",
      "global_step: 40, loss: 0.36928489804267883\n",
      "global_step: 50, loss: 0.4921889305114746\n",
      "global_step: 60, loss: 0.2984669506549835\n",
      "global_step: 70, loss: 0.41466575860977173\n",
      "global_step: 80, loss: 0.2597431242465973\n",
      "global_step: 90, loss: 0.44846025109291077\n",
      "global_step: 100, loss: 0.2612557113170624\n",
      "global_step: 110, loss: 0.2734362781047821\n",
      "global_step: 120, loss: 0.2482375055551529\n",
      "global_step: 130, loss: 0.3017747402191162\n",
      "global_step: 140, loss: 0.2814706563949585\n",
      "global_step: 150, loss: 0.2245887815952301\n",
      "global_step: 160, loss: 0.1818622350692749\n",
      "global_step: 170, loss: 0.1783565878868103\n",
      "global_step: 180, loss: 0.3004911243915558\n",
      "global_step: 190, loss: 0.23544727265834808\n",
      "global_step: 200, loss: 0.11210673302412033\n",
      "global_step: 210, loss: 0.2140013426542282\n",
      "acc: 0.9085051546391752\n",
      "<<<<<<<<Training on epoch1 >>>>>>>>\n",
      "global_step: 0, loss: 0.16113737225532532\n",
      "global_step: 10, loss: 0.3819844722747803\n",
      "global_step: 20, loss: 0.31191298365592957\n",
      "global_step: 30, loss: 0.2676470875740051\n",
      "global_step: 40, loss: 0.2229243963956833\n",
      "global_step: 50, loss: 0.23344430327415466\n",
      "global_step: 60, loss: 0.12716659903526306\n",
      "global_step: 70, loss: 0.4063882529735565\n",
      "global_step: 80, loss: 0.1452133059501648\n",
      "global_step: 90, loss: 0.11764436215162277\n",
      "global_step: 100, loss: 0.3844833970069885\n",
      "global_step: 110, loss: 0.18858246505260468\n",
      "global_step: 120, loss: 0.2658312916755676\n",
      "global_step: 130, loss: 0.23874391615390778\n",
      "global_step: 140, loss: 0.1905524730682373\n",
      "global_step: 150, loss: 0.16613025963306427\n",
      "global_step: 160, loss: 0.22736194729804993\n",
      "global_step: 170, loss: 0.48600277304649353\n",
      "global_step: 180, loss: 0.20486798882484436\n",
      "global_step: 190, loss: 0.15411564707756042\n",
      "global_step: 200, loss: 0.32540929317474365\n",
      "global_step: 210, loss: 0.17872367799282074\n",
      "acc: 0.9162371134020618\n",
      "<<<<<<<<Training on epoch2 >>>>>>>>\n",
      "global_step: 0, loss: 0.08170896023511887\n",
      "global_step: 10, loss: 0.05106499791145325\n",
      "global_step: 20, loss: 0.42401307821273804\n",
      "global_step: 30, loss: 0.21681590378284454\n",
      "global_step: 40, loss: 0.11078416556119919\n",
      "global_step: 50, loss: 0.17351332306861877\n",
      "global_step: 60, loss: 0.14000213146209717\n",
      "global_step: 70, loss: 0.2138313204050064\n",
      "global_step: 80, loss: 0.35188737511634827\n",
      "global_step: 90, loss: 0.18206870555877686\n",
      "global_step: 100, loss: 0.35664287209510803\n",
      "global_step: 110, loss: 0.3264721632003784\n",
      "global_step: 120, loss: 0.1966327577829361\n",
      "global_step: 130, loss: 0.30078840255737305\n",
      "global_step: 140, loss: 0.1338614821434021\n",
      "global_step: 150, loss: 0.13718536496162415\n",
      "global_step: 160, loss: 0.15875497460365295\n",
      "global_step: 170, loss: 0.18622159957885742\n",
      "global_step: 180, loss: 0.12003210932016373\n",
      "global_step: 190, loss: 0.1810252070426941\n",
      "global_step: 200, loss: 0.11082835495471954\n",
      "global_step: 210, loss: 0.05080297961831093\n",
      "acc: 0.9175257731958762\n",
      "<<<<<<<<Training on epoch3 >>>>>>>>\n",
      "global_step: 0, loss: 0.11829113215208054\n",
      "global_step: 10, loss: 0.24172309041023254\n",
      "global_step: 20, loss: 0.0679459422826767\n",
      "global_step: 30, loss: 0.18386055529117584\n",
      "global_step: 40, loss: 0.12803134322166443\n",
      "global_step: 50, loss: 0.27781689167022705\n",
      "global_step: 60, loss: 0.16978351771831512\n",
      "global_step: 70, loss: 0.023453393951058388\n",
      "global_step: 80, loss: 0.132248654961586\n",
      "global_step: 90, loss: 0.07553567737340927\n",
      "global_step: 100, loss: 0.10356198251247406\n",
      "global_step: 110, loss: 0.22183798253536224\n",
      "global_step: 120, loss: 0.2789453864097595\n",
      "global_step: 130, loss: 0.23860052227973938\n",
      "global_step: 140, loss: 0.05729649215936661\n",
      "global_step: 150, loss: 0.10838880389928818\n",
      "global_step: 160, loss: 0.11819612234830856\n",
      "global_step: 170, loss: 0.20339368283748627\n",
      "global_step: 180, loss: 0.4168683588504791\n",
      "global_step: 190, loss: 0.3200303912162781\n",
      "global_step: 200, loss: 0.07389609515666962\n",
      "global_step: 210, loss: 0.34845060110092163\n",
      "acc: 0.9097938144329897\n",
      "<<<<<<<<Training on epoch4 >>>>>>>>\n",
      "global_step: 0, loss: 0.18004389107227325\n",
      "global_step: 10, loss: 0.13261163234710693\n",
      "global_step: 20, loss: 0.0445336289703846\n",
      "global_step: 30, loss: 0.023066414520144463\n",
      "global_step: 40, loss: 0.4224727749824524\n",
      "global_step: 50, loss: 0.11077497899532318\n",
      "global_step: 60, loss: 0.2020731121301651\n",
      "global_step: 70, loss: 0.01757316291332245\n",
      "global_step: 80, loss: 0.0867011621594429\n",
      "global_step: 90, loss: 0.01531387772411108\n",
      "global_step: 100, loss: 0.11497854441404343\n",
      "global_step: 110, loss: 0.16310282051563263\n",
      "global_step: 120, loss: 0.2642286717891693\n",
      "global_step: 130, loss: 0.15074290335178375\n",
      "global_step: 140, loss: 0.047698572278022766\n",
      "global_step: 150, loss: 0.01674436777830124\n",
      "global_step: 160, loss: 0.14181026816368103\n",
      "global_step: 170, loss: 0.034097205847501755\n",
      "global_step: 180, loss: 0.11902253329753876\n",
      "global_step: 190, loss: 0.01269827876240015\n",
      "global_step: 200, loss: 0.08838619291782379\n",
      "global_step: 210, loss: 0.027139998972415924\n",
      "acc: 0.913659793814433\n"
     ]
    }
   ],
   "source": [
    "train(epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "test = \"这家酒店不错，饭很好吃\"\n",
    "with torch.inference_mode():\n",
    "    test_tensor = tokenizer(test, return_tensors=\"pt\")\n",
    "    test_tensor = {k: v.cuda() for k, v, in test_tensor.items()}\n",
    "    test_result = model(**test_tensor).logits\n",
    "    pred = torch.argmax(test_result, dim=-1)\n",
    "    print(pred.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 创建pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'LABEL_1', 'score': 0.9989665746688843}]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"这家酒店不错，饭很好吃\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
